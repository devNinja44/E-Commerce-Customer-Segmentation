{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Customer Segmentation Pipeline\n",
    "\n",
    "This notebook implements an unsupervised learning pipeline for customer segmentation in an e-commerce scenario. The goal is to identify distinct customer groups based on behavioral and transactional data using dimensionality reduction and clustering techniques.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Data Acquisition and Exploration](#data)\n",
    "3. [Data Preprocessing](#preprocessing)\n",
    "4. [Dimensionality Reduction](#dim_reduction)\n",
    "5. [Clustering](#clustering)\n",
    "6. [Evaluation and Visualization](#evaluation)\n",
    "7. [Cluster Analysis and Interpretation](#analysis)\n",
    "8. [Edge Cases and Robustness](#edge_cases)\n",
    "9. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from src.data_preprocessing import load_data, load_online_retail_data, preprocess_data\n",
    "from src.dimensionality_reduction import reduce_dimensions, compare_dimensionality_reduction_methods\n",
    "from src.clustering import find_optimal_k, cluster_data, compare_clustering_methods\n",
    "from src.evaluation import evaluate_clustering, compare_clustering_results, analyze_clusters, generate_cluster_labels\n",
    "from src.visualization import plot_elbow_method, plot_clusters_2d, plot_clusters_3d, plot_cluster_profiles, create_interactive_scatter\n",
    "from src.config import get_config\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = get_config()\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Dimensionality reduction method: {config['dimensionality_reduction']['method']}\")\n",
    "print(f\"- Clustering method: {config['clustering']['method']}\")\n",
    "print(f\"- Number of components: {config['dimensionality_reduction']['n_components']}\")\n",
    "if config['clustering']['method'] == 'kmeans' or config['clustering']['method'] == 'agglomerative':\n",
    "    print(f\"- Number of clusters: {config['clustering'][config['clustering']['method']]['n_clusters']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "## 2. Data Acquisition and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data or load real data\n",
    "if config['data']['use_synthetic']:\n",
    "    print(f\"Generating synthetic data with {config['data']['n_samples']} samples...\")\n",
    "    # Load real data from Online Retail dataset\n",
    "    df, customer_ids = load_online_retail_data(\"None\")\n",
    "else:\n",
    "    if 'path' in config['data']:\n",
    "        print(f\"Loading data from {config['data']['path']}...\")\n",
    "        df = load_data(config['data']['path'])\n",
    "    else:\n",
    "        print(\"No data path specified. Generating synthetic data instead...\")\n",
    "    # Load real data from Online Retail dataset\n",
    "    df, customer_ids = load_online_retail_data(\"None\")\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the data\n",
    "print(\"Data information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "print(\"Summary statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "missing_df[missing_df['Missing Values'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of numerical features\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove customer_id if present\n",
    "if 'customer_id' in numerical_cols:\n",
    "    numerical_cols.remove('customer_id')\n",
    "\n",
    "# Create histograms\n",
    "fig, axes = plt.subplots(len(numerical_cols), 1, figsize=(10, 4 * len(numerical_cols)))\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    sns.histplot(df[col].dropna(), kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Remove customer_id if present\n",
    "if 'customer_id' in categorical_cols:\n",
    "    categorical_cols.remove('customer_id')\n",
    "\n",
    "if categorical_cols:\n",
    "    fig, axes = plt.subplots(len(categorical_cols), 1, figsize=(10, 4 * len(categorical_cols)))\n",
    "    \n",
    "    # Handle case with only one categorical column\n",
    "    if len(categorical_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        value_counts = df[col].value_counts()\n",
    "        sns.barplot(x=value_counts.index, y=value_counts.values, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "if numerical_cols:\n",
    "    corr_matrix = df[numerical_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "print(\"Preprocessing data...\")\n",
    "print(f\"- Missing values strategy: {config['preprocessing']['missing_values']['strategy']}\")\n",
    "print(f\"- Outlier removal method: {config['preprocessing']['outliers']['method']}\")\n",
    "print(f\"- Scaling method: {config['preprocessing']['scaling']['method']}\")\n",
    "print(f\"- Encoding method: {config['preprocessing']['encoding']['method']}\")\n",
    "\n",
    "# Store customer IDs for later reference\n",
    "customer_ids = None\n",
    "if 'customer_id' in df.columns:\n",
    "\n",
    "# Apply preprocessing pipeline\n",
    "df_processed = preprocess_data(df, config=config['preprocessing'])\n",
    "\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "print(f\"Processed data shape: {df_processed.shape}\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dim_reduction'></a>\n",
    "## 4. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dimensionality reduction\n",
    "print(f\"Applying {config['dimensionality_reduction']['method']} dimensionality reduction...\")\n",
    "\n",
    "# Get method-specific parameters\n",
    "method = config['dimensionality_reduction']['method']\n",
    "n_components = config['dimensionality_reduction']['n_components']\n",
    "method_params = config['dimensionality_reduction'][method]\n",
    "random_state = config['dimensionality_reduction']['random_state']\n",
    "\n",
    "# Apply dimensionality reduction\n",
    "X_reduced, model, additional_info = reduce_dimensions(\n",
    "    df_processed.values,\n",
    "    method=method,\n",
    "    n_components=n_components,\n",
    "    random_state=random_state,\n",
    "    **method_params\n",
    ")\n",
    "\n",
    "print(f\"Reduced data shape: {X_reduced.shape}\")\n",
    "\n",
    "# Display additional information if available\n",
    "if method == 'pca':\n",
    "    print(f\"Explained variance ratio: {additional_info}\")\n",
    "    print(f\"Total explained variance: {sum(additional_info):.4f}\")\n",
    "elif method == 'mds':\n",
    "    print(f\"Stress: {additional_info:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reduced data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], alpha=0.7)\n",
    "plt.title(f'Data after {method.upper()} Dimensionality Reduction')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different dimensionality reduction methods\n",
    "print(\"Comparing different dimensionality reduction methods...\")\n",
    "\n",
    "# Define methods to compare\n",
    "methods_to_compare = ['pca', 'kernel_pca', 'mds', 'umap']\n",
    "\n",
    "# Apply each method\n",
    "dim_reduction_results = compare_dimensionality_reduction_methods(\n",
    "    df_processed.values,\n",
    "    methods=methods_to_compare,\n",
    "    n_components=2\n",
    ")\n",
    "\n",
    "# Extract reduced data for visualization\n",
    "X_dict = {}\n",
    "for method_name, (X_method, _, _) in dim_reduction_results.items():\n",
    "    X_dict[method_name.upper()] = X_method\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (method_name, X_method) in enumerate(X_dict.items()):\n",
    "    axes[i].scatter(X_method[:, 0], X_method[:, 1], alpha=0.7)\n",
    "    axes[i].set_title(f'{method_name} Reduction')\n",
    "    axes[i].set_xlabel('Component 1')\n",
    "    axes[i].set_ylabel('Component 2')\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}